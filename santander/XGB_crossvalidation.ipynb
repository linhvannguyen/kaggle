{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn import grid_search\n",
    "from sklearn import linear_model, metrics, preprocessing\n",
    "from sklearn.feature_selection import RFE,SelectPercentile,f_classif,chi2\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn import metrics\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('./data/train.csv')\n",
    "df_test = pd.read_csv('./data/test.csv')\n",
    "\n",
    "skf_cv = StratifiedKFold(df_train['TARGET'], n_folds=6, shuffle=True, random_state=None) # split target equally\n",
    "def score_model(model,X,t):\n",
    "    #return cross_val_score(model, X, t, cv=6, scoring=\"roc_auc\",n_jobs=3)\n",
    "    return cross_val_score(model, X, t, cv=skf_cv, scoring=\"roc_auc\",n_jobs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove constant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "remove = []\n",
    "for col in df_train.columns:\n",
    "    if df_train[col].std() == 0:\n",
    "        remove.append(col)\n",
    "\n",
    "df_train.drop(remove, axis=1, inplace=True)\n",
    "df_test.drop(remove, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove duplicated columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "remove = []\n",
    "c = df_train.columns\n",
    "for i in range(len(c)-1):\n",
    "    v = df_train[c[i]].values\n",
    "    for j in range(i+1,len(c)):\n",
    "        if np.array_equal(v,df_train[c[j]].values):\n",
    "            remove.append(c[j])\n",
    "\n",
    "df_train.drop(remove, axis=1, inplace=True)\n",
    "df_test.drop(remove, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Replace -999999 in var3 column with most common value 2 \n",
    "df_train = df_train.replace(-999999,2)\n",
    "df_test = df_test.replace(-999999,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi2 & F_classif selected 106 features\n",
      "List of features:['var15', 'imp_op_var40_efect_ult1', 'imp_op_var40_efect_ult3', 'imp_op_var41_efect_ult1', 'imp_op_var41_efect_ult3', 'imp_op_var41_ult1', 'imp_op_var39_efect_ult1', 'imp_op_var39_efect_ult3', 'imp_op_var39_ult1', 'ind_var5_0', 'ind_var5', 'ind_var8_0', 'ind_var8', 'ind_var12_0', 'ind_var12', 'ind_var13_0', 'ind_var13_corto_0', 'ind_var13_corto', 'ind_var13_largo_0', 'ind_var13_largo', 'ind_var13', 'ind_var14_0', 'ind_var24_0', 'ind_var24', 'ind_var25_cte', 'ind_var26_0', 'ind_var26_cte', 'ind_var25_0', 'ind_var30', 'ind_var39_0', 'ind_var41_0', 'num_var4', 'num_var5_0', 'num_var5', 'num_var8_0', 'num_var8', 'num_var12_0', 'num_var12', 'num_var13_0', 'num_var13_corto_0', 'num_var13_corto', 'num_var13_largo_0', 'num_var13_largo', 'num_var13', 'num_var14_0', 'num_var24_0', 'num_var24', 'num_var26_0', 'num_var25_0', 'num_var30_0', 'num_var30', 'num_var35', 'num_var39_0', 'num_var41_0', 'num_var42_0', 'num_var42', 'saldo_var5', 'saldo_var12', 'saldo_var13_corto', 'saldo_var13_largo', 'saldo_var13', 'saldo_var24', 'saldo_var26', 'saldo_var25', 'saldo_var30', 'saldo_var42', 'var36', 'imp_aport_var13_hace3', 'imp_trans_var37_ult1', 'ind_var43_recib_ult1', 'num_aport_var13_hace3', 'num_var22_ult1', 'num_med_var22_ult3', 'num_meses_var5_ult3', 'num_meses_var8_ult3', 'num_meses_var12_ult3', 'num_meses_var13_corto_ult3', 'num_meses_var13_largo_ult3', 'num_op_var40_efect_ult1', 'num_op_var40_efect_ult3', 'num_op_var41_efect_ult1', 'num_op_var41_efect_ult3', 'num_op_var39_efect_ult1', 'num_op_var39_efect_ult3', 'num_var43_recib_ult1', 'num_var45_hace2', 'num_var45_ult3', 'saldo_medio_var5_hace2', 'saldo_medio_var5_hace3', 'saldo_medio_var5_ult1', 'saldo_medio_var5_ult3', 'saldo_medio_var8_hace2', 'saldo_medio_var8_ult1', 'saldo_medio_var8_ult3', 'saldo_medio_var12_hace2', 'saldo_medio_var12_hace3', 'saldo_medio_var12_ult1', 'saldo_medio_var12_ult3', 'saldo_medio_var13_corto_hace2', 'saldo_medio_var13_corto_hace3', 'saldo_medio_var13_corto_ult1', 'saldo_medio_var13_corto_ult3', 'saldo_medio_var13_largo_hace2', 'saldo_medio_var13_largo_ult1', 'saldo_medio_var13_largo_ult3', 'var38']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nguyen/anaconda/lib/python2.7/site-packages/sklearn/preprocessing/data.py:167: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    }
   ],
   "source": [
    "Xdf_tr = df_train.drop('TARGET', 1)\n",
    "tdf_tr = df_train.TARGET\n",
    "\n",
    "from sklearn.preprocessing import Binarizer, scale\n",
    "\n",
    "p = 30 # percentage of selected features\n",
    "\n",
    "X_bin = Binarizer().fit_transform(scale(Xdf_tr))\n",
    "selectChi2 = SelectPercentile(chi2, percentile=p).fit(X_bin, tdf_tr)\n",
    "selectF_classif = SelectPercentile(f_classif, percentile=p).fit(Xdf_tr, tdf_tr)\n",
    "\n",
    "chi2_selected = selectChi2.get_support()\n",
    "chi2_selected_features = [ f for i,f in enumerate(Xdf_tr.columns) if chi2_selected[i]]\n",
    "\n",
    "f_classif_selected = selectF_classif.get_support()\n",
    "f_classif_selected_features = [ f for i,f in enumerate(Xdf_tr.columns) if f_classif_selected[i]]\n",
    "\n",
    "\n",
    "selected = chi2_selected | f_classif_selected\n",
    "print('Chi2 & F_classif selected {} features'.format(selected.sum()))\n",
    "features = [ f for f,s in zip(Xdf_tr.columns, selected) if s]\n",
    "\n",
    "print('List of features:{}'.format(features))\n",
    "Xdf=df_train[features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from sklearn import preprocessing\n",
    "#X_tr = preprocessing.scale(Xdf.as_matrix())\n",
    "\n",
    "X_tr = Xdf.as_matrix()\n",
    "t_tr = df_train['TARGET'].as_matrix()\n",
    "\n",
    "N_tr=np.shape(X_tr)[0]\n",
    "D=np.shape(X_tr)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# classifier\n",
    "# http://xgboost.readthedocs.org/en/latest/parameter.html\n",
    "# http://xgboost.readthedocs.org/en/latest/param_tuning.html\n",
    "clf = xgb.XGBClassifier(\n",
    "      objective= 'binary:logistic', \n",
    "      learning_rate=0.02, \n",
    "      n_estimators=200,\n",
    "      max_depth=5,\n",
    "      subsample=0.85,\n",
    "      colsample_bytree=0.85,\n",
    "      nthread=3,\n",
    "      silent = 1,\n",
    "      seed=8\n",
    ")\n",
    "\n",
    "cv_scores=score_model(clf, X_tr,t_tr)\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Report\n",
      "AUC Score (cross-validation): 0.838992 (+- 0.005478)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nModel Report\")\n",
    "print(\"AUC Score (cross-validation): %f (+- %f)\" % (cv_scores.mean(), cv_scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf = xgb.XGBClassifier(\n",
    "      objective= 'binary:logistic', \n",
    "      n_estimators=500,\n",
    "      nthread=3,\n",
    "      silent = 1,\n",
    "      seed=8\n",
    ")\n",
    "parameters = {\n",
    "    'max_depth': [6,7,8],\n",
    "    'learning_rate': [0.015, 0.0175, 0.02],\n",
    "    'subsample': [0.85, 0.9],\n",
    "    'colsample_bytree': [0.85, 0.9]\n",
    "}\n",
    "\n",
    "clf = grid_search.GridSearchCV(clf, parameters, n_jobs=3, cv=skf_cv, scoring='roc_auc')\n",
    "clf.fit(X_tr, t_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_parameters, score, _ = max(clf.grid_scores_, key=lambda x: x[1])\n",
    "print('Raw AUC score:', score)\n",
    "for param_name in sorted(best_parameters.keys()):\n",
    "    print(\"%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print clf.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
