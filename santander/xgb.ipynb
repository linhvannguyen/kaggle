{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn import linear_model, metrics, preprocessing\n",
    "from sklearn.feature_selection import RFE,SelectPercentile,f_classif,chi2\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('./data/train.csv')\n",
    "df_test = pd.read_csv('./data/test.csv')\n",
    "\n",
    "skf_cv = StratifiedKFold(df_train['TARGET'], n_folds=6, shuffle=True, random_state=None) # split target equally\n",
    "def score_model(model,X,t):\n",
    "    #return cross_val_score(model, X, t, cv=6, scoring=\"roc_auc\",n_jobs=3)\n",
    "    return cross_val_score(model, X, t, cv=skf_cv, scoring=\"roc_auc\",n_jobs=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove constant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "remove = []\n",
    "for col in df_train.columns:\n",
    "    if df_train[col].std() == 0:\n",
    "        remove.append(col)\n",
    "\n",
    "df_train.drop(remove, axis=1, inplace=True)\n",
    "df_test.drop(remove, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove duplicated columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "remove = []\n",
    "c = df_train.columns\n",
    "for i in range(len(c)-1):\n",
    "    v = df_train[c[i]].values\n",
    "    for j in range(i+1,len(c)):\n",
    "        if np.array_equal(v,df_train[c[j]].values):\n",
    "            remove.append(c[j])\n",
    "\n",
    "df_train.drop(remove, axis=1, inplace=True)\n",
    "df_test.drop(remove, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Replace -999999 in var3 column with most common value 2 \n",
    "df_train = df_train.replace(-999999,2)\n",
    "df_test = df_test.replace(-999999,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi2 & F_classif selected 173 features\n",
      "List of features:['var3', 'var15', 'imp_op_var39_comer_ult1', 'imp_op_var40_efect_ult1', 'imp_op_var40_efect_ult3', 'imp_op_var41_comer_ult1', 'imp_op_var41_efect_ult1', 'imp_op_var41_efect_ult3', 'imp_op_var41_ult1', 'imp_op_var39_efect_ult1', 'imp_op_var39_efect_ult3', 'imp_op_var39_ult1', 'imp_sal_var16_ult1', 'ind_var1', 'ind_var5_0', 'ind_var5', 'ind_var8_0', 'ind_var8', 'ind_var12_0', 'ind_var12', 'ind_var13_0', 'ind_var13_corto_0', 'ind_var13_corto', 'ind_var13_largo_0', 'ind_var13_largo', 'ind_var13', 'ind_var14_0', 'ind_var14', 'ind_var17_0', 'ind_var19', 'ind_var20_0', 'ind_var20', 'ind_var24_0', 'ind_var24', 'ind_var25_cte', 'ind_var26_0', 'ind_var26_cte', 'ind_var25_0', 'ind_var30_0', 'ind_var30', 'ind_var31_0', 'ind_var31', 'ind_var33_0', 'ind_var33', 'ind_var39_0', 'ind_var40', 'ind_var41_0', 'ind_var44_0', 'num_var1', 'num_var4', 'num_var5_0', 'num_var5', 'num_var8_0', 'num_var8', 'num_var12_0', 'num_var12', 'num_var13_0', 'num_var13_corto_0', 'num_var13_corto', 'num_var13_largo_0', 'num_var13_largo', 'num_var13', 'num_var14_0', 'num_var14', 'num_var20_0', 'num_var20', 'num_var24_0', 'num_var24', 'num_var26_0', 'num_var25_0', 'num_op_var41_hace2', 'num_op_var41_ult1', 'num_op_var41_ult3', 'num_op_var39_hace2', 'num_op_var39_ult1', 'num_op_var39_ult3', 'num_var30_0', 'num_var30', 'num_var31_0', 'num_var31', 'num_var33_0', 'num_var35', 'num_var39_0', 'num_var40', 'num_var41_0', 'num_var42_0', 'num_var42', 'num_var44_0', 'saldo_var1', 'saldo_var5', 'saldo_var12', 'saldo_var13_corto', 'saldo_var13_largo', 'saldo_var13', 'saldo_var14', 'saldo_var20', 'saldo_var24', 'saldo_var26', 'saldo_var25', 'saldo_var30', 'saldo_var31', 'saldo_var40', 'saldo_var42', 'var36', 'delta_imp_aport_var13_1y3', 'delta_num_aport_var13_1y3', 'imp_aport_var13_hace3', 'imp_aport_var13_ult1', 'imp_reemb_var17_ult1', 'imp_var43_emit_ult1', 'imp_trans_var37_ult1', 'ind_var10_ult1', 'ind_var10cte_ult1', 'ind_var9_cte_ult1', 'ind_var9_ult1', 'ind_var43_emit_ult1', 'ind_var43_recib_ult1', 'num_aport_var13_hace3', 'num_aport_var13_ult1', 'num_ent_var16_ult1', 'num_var22_hace2', 'num_var22_ult1', 'num_var22_ult3', 'num_med_var22_ult3', 'num_med_var45_ult3', 'num_meses_var5_ult3', 'num_meses_var8_ult3', 'num_meses_var12_ult3', 'num_meses_var13_corto_ult3', 'num_meses_var13_largo_ult3', 'num_meses_var17_ult3', 'num_meses_var39_vig_ult3', 'num_meses_var44_ult3', 'num_op_var39_comer_ult1', 'num_op_var40_efect_ult1', 'num_op_var40_efect_ult3', 'num_op_var41_comer_ult1', 'num_op_var41_efect_ult1', 'num_op_var41_efect_ult3', 'num_op_var39_efect_ult1', 'num_op_var39_efect_ult3', 'num_reemb_var17_ult1', 'num_sal_var16_ult1', 'num_var43_emit_ult1', 'num_var43_recib_ult1', 'num_trasp_var11_ult1', 'num_var45_hace2', 'num_var45_hace3', 'num_var45_ult1', 'num_var45_ult3', 'saldo_medio_var5_hace2', 'saldo_medio_var5_hace3', 'saldo_medio_var5_ult1', 'saldo_medio_var5_ult3', 'saldo_medio_var8_hace2', 'saldo_medio_var8_hace3', 'saldo_medio_var8_ult1', 'saldo_medio_var8_ult3', 'saldo_medio_var12_hace2', 'saldo_medio_var12_hace3', 'saldo_medio_var12_ult1', 'saldo_medio_var12_ult3', 'saldo_medio_var13_corto_hace2', 'saldo_medio_var13_corto_hace3', 'saldo_medio_var13_corto_ult1', 'saldo_medio_var13_corto_ult3', 'saldo_medio_var13_largo_hace2', 'saldo_medio_var13_largo_hace3', 'saldo_medio_var13_largo_ult1', 'saldo_medio_var13_largo_ult3', 'saldo_medio_var17_hace2', 'saldo_medio_var44_hace2', 'var38']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nguyen/anaconda/lib/python2.7/site-packages/sklearn/preprocessing/data.py:167: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    }
   ],
   "source": [
    "Xdf_tr = df_train.drop('TARGET', 1)\n",
    "tdf_tr = df_train.TARGET\n",
    "\n",
    "from sklearn.preprocessing import Binarizer, scale\n",
    "\n",
    "p = 50 # percentage of selected features\n",
    "\n",
    "X_bin = Binarizer().fit_transform(scale(Xdf_tr))\n",
    "selectChi2 = SelectPercentile(chi2, percentile=p).fit(X_bin, tdf_tr)\n",
    "selectF_classif = SelectPercentile(f_classif, percentile=p).fit(Xdf_tr, tdf_tr)\n",
    "\n",
    "chi2_selected = selectChi2.get_support()\n",
    "chi2_selected_features = [ f for i,f in enumerate(Xdf_tr.columns) if chi2_selected[i]]\n",
    "\n",
    "f_classif_selected = selectF_classif.get_support()\n",
    "f_classif_selected_features = [ f for i,f in enumerate(Xdf_tr.columns) if f_classif_selected[i]]\n",
    "\n",
    "\n",
    "selected = chi2_selected | f_classif_selected\n",
    "print('Chi2 & F_classif selected {} features'.format(selected.sum()))\n",
    "features = [ f for f,s in zip(Xdf_tr.columns, selected) if s]\n",
    "\n",
    "print('List of features:{}'.format(features))\n",
    "Xdf=df_train[features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# classifier\n",
    "# http://xgboost.readthedocs.org/en/latest/parameter.html\n",
    "# http://xgboost.readthedocs.org/en/latest/param_tuning.html\n",
    "clf = xgb.XGBClassifier(\n",
    "      objective= 'binary:logistic',    \n",
    "      learning_rate=0.0175, \n",
    "      n_estimators=500,\n",
    "      max_depth=8,\n",
    "      subsample=0.9,\n",
    "      colsample_bytree=0.87,\n",
    "      nthread=4,\n",
    "      silent = 1,\n",
    "      seed=8\n",
    ")\n",
    "# best observed: learning_rate=0.0175, n_estimators=400,max_depth=8,subsample=0.9,colsample_bytree=0.87,  seed=8\n",
    "\n",
    "X_tr = Xdf.as_matrix()\n",
    "t_tr = df_train['TARGET'].as_matrix()\n",
    "\n",
    "cv_scores={}\n",
    "cv_scores['XGB']=score_model(clf, X_tr,t_tr)\n",
    "print cv_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Split up the data for early stopping\n",
    "X_fit, X_eval, t_fit, t_eval = train_test_split(X_tr, t_tr, test_size=0.25, random_state=42)\n",
    "\n",
    "clf.fit(X_tr, t_tr, early_stopping_rounds=50, eval_metric=\"auc\", eval_set=[(X_eval, t_eval)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = df_test[features].as_matrix()\n",
    "t_pred=clf.predict_proba(X_test)[:,1]\n",
    "plt.plot(t_pred)\n",
    "\n",
    "id_test = df_test['ID']\n",
    "submission = pd.DataFrame({\"ID\":id_test, \"TARGET\": t_pred})\n",
    "submission.to_csv(\"./data/submission_xgb.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
